{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_NDFrameIndexer' from 'pandas.core.indexing' (C:\\Users\\Lovly\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-deef54bac2ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# import necessary packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mX:\\Work\\GeoTemp\\CCDR\\Python\\common.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeodataframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_postgis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopandas\\geoseries.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoPandasBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_series_unary_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_CoordinateIndexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopandas\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_NDFrameIndexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiPoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiLineString\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiPolygon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcascaded_union\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munary_union\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_NDFrameIndexer' from 'pandas.core.indexing' (C:\\Users\\Lovly\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py)"
     ]
    }
   ],
   "source": [
    "from common import *  # import necessary packages\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directories\n",
    "DATA_DIR = \"../data/\"\n",
    "SAR_loc = \"C:/development/CDCC-data/SAR/\"\n",
    "\n",
    "# Make cache dir if needed\n",
    "CACHE_DIR = f\"{DATA_DIR}cache/\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_map = {\n",
    "    \"NPL\": 175  # TODO: Add others\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_factor(x):\n",
    "    \"\"\"A polynomial fit to average damage across multiple sectors relative \n",
    "    to water depth in meters in Asia.\n",
    "\n",
    "    The sectors are commercial, industry, transport, agriculture, infrastructure and residential.\n",
    "\n",
    "    Values are capped between 0 and 1, where values >= 6m = 1\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] JRC, 2017\n",
    "    \"\"\"\n",
    "    return np.maximum(0.0, np.minimum(1.0, 0.00723*x**3 - 0.1*x**2 + 0.506*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(b):\n",
    "    with output:\n",
    "        print(\"Running analysis...\")\n",
    "\n",
    "    # Get user input\n",
    "    country = country_dd.value\n",
    "    exp_cat = exp_cat_dd.value\n",
    "    time_horizon = time_horizon_dd.value\n",
    "    rcp_scenario = rcp_scenario_dd.value\n",
    "\n",
    "    target_ADM = adm_dd.value\n",
    "    adm_name = target_ADM.replace('_', '')\n",
    "\n",
    "    agg_criteria = agg_dd.value\n",
    "    min_haz_threshold = min_haz_slider.value\n",
    "\n",
    "    valid_RPs = [10, 100, 1000]\n",
    "\n",
    "    # Testing data file locations\n",
    "    # TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "\n",
    "    # pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "    pop_fn = f\"{DATA_DIR}/cache/WorldPop20_{country}_ppp_UNadj_constrained.tif\"\n",
    "\n",
    "    # Flood data location (TODO: replace with pointer to\n",
    "    #  downloaded data store)\n",
    "    flood_RP_data_loc = f\"C:/development/CDCC-data/SAR/HZD/Flood/{country}/\"\n",
    "\n",
    "    # Load or save ISO3 country list\n",
    "    iso3_path = f\"{DATA_DIR}cache/iso3.json\"\n",
    "    if not os.path.exists(iso3_path):\n",
    "        resp = json.loads(requests.get(f\"https://www.worldpop.org/rest/data/pop/wpgp?iso3={country}\").text)\n",
    "\n",
    "        with open(iso3_path, 'w') as outfile:\n",
    "            json.dump(resp, outfile)\n",
    "    else:\n",
    "        with open(iso3_path, 'r') as infile:\n",
    "            resp = json.load(infile)\n",
    "\n",
    "\n",
    "    # TODO: User to select population data set\n",
    "    # Target population data files are extracted from the JSON list downloaded above\n",
    "    metadata = resp['data'][1]\n",
    "    data_src = metadata['files']\n",
    "\n",
    "    # Save population data to cache location\n",
    "    for data_fn in tqdm(data_src):\n",
    "        fid = metadata['id']\n",
    "        cache_fn = os.path.basename(data_fn)\n",
    "\n",
    "        # Look for indicated file in cache directory\n",
    "        # Use the data file if it is found, but warn the user. \n",
    "        # (if data is incorrect or corrupted, they should delete it from cache)\n",
    "        if f\"{fid}_{cache_fn}\" in os.listdir(f\"{DATA_DIR}/cache\"):\n",
    "            warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Write to cache file if not found\n",
    "        with open(f\"{DATA_DIR}/cache/{fid}_{cache_fn}\", \"wb\") as handle:\n",
    "            response = requests.get(data_fn)\n",
    "            handle.write(response.content)\n",
    "\n",
    "\n",
    "    # Run analysis\n",
    "    \n",
    "    # Open population dataset\n",
    "    pop_data = rxr.open_rasterio(pop_fn)\n",
    "\n",
    "    # Indicate -1 values as representing no data.\n",
    "    pop_data.rio.write_nodata(-1, inplace=True)\n",
    "\n",
    "    # Load ADM2 based on country code value\n",
    "    try:\n",
    "        adm_dataset = gpd.read_file(os.path.join(SAR_loc, \"ADM_012.gpkg\"), layer=target_ADM)\n",
    "    except ValueError:\n",
    "        # Layer names have not been standardized yet, so try again without the underscore\n",
    "        adm_dataset = gpd.read_file(os.path.join(SAR_loc, \"NPL_ADM.gpkg\"), layer=adm_name)\n",
    "\n",
    "    \n",
    "    adm_data = adm_dataset.loc[adm_dataset.ADM0_CODE == country_code_map[country], :]\n",
    "\n",
    "    # Prep result structure\n",
    "    pop_sum_cols = [f\"RP{rp_i}_pop_sum\" for rp_i in valid_RPs]\n",
    "    EAI_cols = [f\"RP{rp_i}_EAI\" for rp_i in valid_RPs]\n",
    "    result_df = adm_data.loc[:, [f\"{adm_name}_CODE\", f\"{adm_name}_NAME\", \"geometry\"]]\n",
    "    result_df.loc[:, pop_sum_cols + EAI_cols] = 0\n",
    "\n",
    "    # pop_bounds = pop_data.rio.bounds()\n",
    "    # crs = result_df.crs\n",
    "    for rp in valid_RPs:\n",
    "        \n",
    "        # Get total population for each ADM2 region\n",
    "        pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=pop_fn, stats=[\"sum\"])\n",
    "        \n",
    "        result_df[f\"{adm_name}_Pop\"] = [x['sum'] for x in pop_per_ADM]\n",
    "\n",
    "        # Load corresponding flood dataset\n",
    "        flood_data = rxr.open_rasterio(flood_RP_data_loc+f\"RP{rp}.tif\")\n",
    "\n",
    "        # Reproject and clip raster to same bounds as population data\n",
    "        flood_data = flood_data.rio.reproject_match(pop_data)\n",
    "\n",
    "        # Get raw array values for population and flood\n",
    "        fld_array = flood_data[0].values\n",
    "        fld_array[fld_array < min_haz_threshold] = np.nan  # Set values below min threshold to nan\n",
    "        # fld_array[fld_array > max_haz_threshold] = max_haz_threshold  # Cap large values to maximum threshold value\n",
    "\n",
    "        # Assign impact factor\n",
    "        impact_array = damage_factor(fld_array)\n",
    "\n",
    "        # Create raster from array\n",
    "        impact_rst = xr.DataArray(np.array([impact_array]).astype(np.float32), coords=flood_data.coords, dims=flood_data.dims)\n",
    "        # impact_rst.plot()  # to preview\n",
    "\n",
    "        # Impact x Pop\n",
    "        # Calculate affected population in ADM\n",
    "        affected_pop = pop_data.where(impact_rst.values > 0)\n",
    "        affected_pop = affected_pop.where(affected_pop > 0)\n",
    "\n",
    "        # Probability of return period\n",
    "        # Essentially the same as 1/RP, but accounts for cases where RP == 1\n",
    "        RPp = 1 - np.exp(-1/rp)\n",
    "\n",
    "        RPi_EAI = affected_pop * RPp\n",
    "\n",
    "        # Get affected population per ADM\n",
    "        affected_pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=affected_pop.data[0], \n",
    "                                            stats=[\"sum\"], affine=affected_pop.rio.transform(), nodata=-999)\n",
    "        result_df[f\"RP{rp}_pop_sum\"] = [x['sum'] for x in affected_pop_per_ADM]\n",
    "\n",
    "\n",
    "        EAI_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=RPi_EAI.data[0], \n",
    "                                    stats=[\"sum\"], affine=RPi_EAI.rio.transform(), nodata=-999)\n",
    "        result_df[f\"RP{rp}_EAI\"] = [x['sum'] for x in EAI_per_ADM]\n",
    "\n",
    "            \n",
    "    # Sum all EAI to get total EAI across all RPs\n",
    "    result_df.loc[:, \"Pop_EAI\"] = result_df.loc[:, result_df.columns.str.contains('_EAI')].sum(axis=1)\n",
    "\n",
    "    # Calculate Pop_EAI%\n",
    "    result_df.loc[:, \"Pop_EAI%\"] = result_df.loc[:, \"Pop_EAI\"] / result_df.loc[:, f\"{adm_name}_Pop\"]  # Percent affected population per year\n",
    "\n",
    "    # Aggregated to ADM1\n",
    "    agg_func = getattr(np, agg_criteria)\n",
    "    result_df.loc[:, f\"ADM1_agg_{agg_criteria}\"] = agg_func(result_df.loc[:, \"Pop_EAI%\"])\n",
    "\n",
    "    # Write table of total population in each class, in each ADM2\n",
    "    result_df.to_csv(f\"{country}_functional_example_results.csv\", index=False)\n",
    "\n",
    "    # Export geopackage\n",
    "    result_df.to_file(f\"{country}_{adm_name}_test.gpkg\")\n",
    "    \n",
    "    with output:\n",
    "        print(\"Finished analysis.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6194eff14bec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m country_dd = widgets.Dropdown(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nepal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NPL'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NPL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "country_dd = widgets.Dropdown(\n",
    "    options=[('Nepal', 'NPL'), ],\n",
    "    value='NPL',\n",
    "    description='Country:',\n",
    ")\n",
    "\n",
    "exp_cat_dd = widgets.Dropdown(\n",
    "    options=[(\"Population\", \"population\"), (\"Land Cover\", \"land_cover\")],\n",
    "    value='population',\n",
    "    description='Exposure Category:',\n",
    ")\n",
    "\n",
    "time_horizon_dd = widgets.Dropdown(\n",
    "    options=[2050, 2080],\n",
    "    value=2050,\n",
    "    description='Time Horizon:',\n",
    ")\n",
    "\n",
    "rcp_scenario_dd = widgets.Dropdown(\n",
    "    options=[\"2.6\", \"4.5\", \"6.5\", \"8.5\"],\n",
    "    value=\"4.5\",\n",
    "    description='RCP Scenario:',\n",
    ")\n",
    "\n",
    "adm_dd = widgets.Dropdown(\n",
    "    options=['ADM_1', 'ADM_2', 'ADM_3'],\n",
    "    value='ADM_2',\n",
    "    description='ADM Level:',\n",
    ")\n",
    "\n",
    "agg_dd = widgets.Dropdown(\n",
    "    options=['mean', 'max'],\n",
    "    value='mean',\n",
    "    description='Aggregation method:',\n",
    "    tooltip='Method to aggregate up to ADM1',\n",
    ")\n",
    "\n",
    "min_haz_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.01,\n",
    "    max=10.0,\n",
    "    step=0.05,\n",
    "    description=\"Minimum Threshold:\",\n",
    ")\n",
    "\n",
    "\n",
    "# Run button to perform analysis\n",
    "run_button = widgets.Button(\n",
    "    description='Run Analysis',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to run analysis with selected options',\n",
    "    # icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "run_button.on_click(run_analysis)\n",
    "\n",
    "# class_range = range(3, 11)  # remember that python uses end-exclusive range, so this is 3-10\n",
    "# selected_bin_edges = [0.5, 1, 1.5, 2, 2.5, 3]\n",
    "# min_haz_threshold = np.min(selected_bin_edges)  # determine min/max values from user-selected edges\n",
    "# max_haz_threshold = np.max(selected_bin_edges)\n",
    "# selected_bin_edges += [np.inf] # add inf last to cover anything above max threshold.\n",
    "\n",
    "# num_bins = len(selected_bin_edges)-1  # default number of bins, within the range of `class_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'country_dd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7cae87b22470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry_dd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_cat_dd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_horizon_dd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrcp_scenario_dd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madm_dd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'country_dd' is not defined"
     ]
    }
   ],
   "source": [
    "display(country_dd)\n",
    "display(exp_cat_dd)\n",
    "display(time_horizon_dd)\n",
    "display(rcp_scenario_dd)\n",
    "display(adm_dd)\n",
    "display(agg_dd)\n",
    "display(min_haz_slider)\n",
    "display(run_button)\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d8b26c4f649b8a27f8996ac75dd87b5987470d4d00d1b2c02ba594e155f4b5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
