{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ad9a5b-154d-4f7a-8579-59487c6a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import tempfile, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import contextily as ctx\n",
    "# from contextily import Place\n",
    "\n",
    "# Addresses SSL error when interacting with worldpop data\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d53d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directories\n",
    "DATA_DIR = \"X:/Work/GeoTemp/CCDR/Nepal/data_script/\"\n",
    "ADM_bound = \"X:/Work/GeoTemp/CCDR/Nepal/data_script/adm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_factor(x):\n",
    "    \"\"\"A polynomial fit to average damage across multiple sectors relative \n",
    "    to water depth in meters in Asia.\n",
    "\n",
    "    The sectors are commercial, industry, transport, agriculture, infrastructure and residential.\n",
    "\n",
    "    Values are capped between 0 and 1, where values >= 6m = 1\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] JRC, 2017\n",
    "    \"\"\"\n",
    "    return np.maximum(0.0, np.minimum(1.0, 0.00723*x**3 - 0.1*x**2 + 0.506*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526bfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stub for user input\n",
    "# TODO: Make this nicer and more accessible for users\n",
    "\n",
    "country = \"NPL\"\n",
    "exp_cat = [\"population\", \"land cover\"]\n",
    "time_horizon = [2050, 2080]\n",
    "rcp_scenario = [\"2.6\", \"4.5\", \"6.5\", \"8.5\"]\n",
    "\n",
    "# Settings\n",
    "agg_criteria = \"mean\"  # [\"max\", \"mean\"]\n",
    "class_range = range(3, 11)  # remember that python uses end-exclusive range, so this is 3-10\n",
    "\n",
    "selected_bin_edges = [0.5, 1, 1.5, 2, 2.5, 3]\n",
    "min_haz_threshold = np.min(selected_bin_edges)  # determine min/max values from user-selected edges\n",
    "max_haz_threshold = np.max(selected_bin_edges)\n",
    "selected_bin_edges += [np.inf] # add inf last to cover anything above max threshold.\n",
    "\n",
    "num_bins = len(selected_bin_edges)-1  # default number of bins, within the range of `class_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc09e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data file locations\n",
    "# TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "\n",
    "# pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "pop_fn = f\"{DATA_DIR}/cache/WorldPop20_{country}_ppp_UNadj_constrained.tif\"\n",
    "\n",
    "# Flood data location (TODO: replace with pointer to downloaded data store)\n",
    "flood_RP_data_loc = f\"X:/Work/GeoTemp/CCDR/Nepal/data_script/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d7319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_map = {\n",
    "    \"NPL\": 175\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712e53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or save ISO3 country list\n",
    "iso3_path = f\"{DATA_DIR}cache/iso3.json\"\n",
    "if not os.path.exists(iso3_path):\n",
    "    resp = json.loads(requests.get(f\"https://www.worldpop.org/rest/data/pop/wpgp?iso3={country}\").text)\n",
    "\n",
    "    with open(iso3_path, 'w') as outfile:\n",
    "        json.dump(resp, outfile)\n",
    "else:\n",
    "    with open(iso3_path, 'r') as infile:\n",
    "        resp = json.load(infile)\n",
    "\n",
    "\n",
    "# TODO: User to select population data set\n",
    "# Target population data files are extracted from the JSON list downloaded above\n",
    "metadata = resp['data'][1]\n",
    "data_src = metadata['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbd775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:27<00:00, 27.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save population data to cache location\n",
    "for data_fn in tqdm(data_src):\n",
    "    fid = metadata['id']\n",
    "    cache_fn = os.path.basename(data_fn)\n",
    "\n",
    "    # Look for indicated file in cache directory\n",
    "    # Use the data file if it is found, but warn the user. \n",
    "    # (if data is incorrect or corrupted, they should delete it from cache)\n",
    "    if f\"{fid}_{cache_fn}\" in os.listdir(f\"{DATA_DIR}/cache\"):\n",
    "        warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Write to cache file if not found\n",
    "    with open(f\"{DATA_DIR}/cache/{fid}_{cache_fn}\", \"wb\") as handle:\n",
    "        response = requests.get(data_fn)\n",
    "        handle.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d21d7f",
   "metadata": {},
   "source": [
    "Load country boundaries from ADM geopackage file which includes ISO3 code related to country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f9101d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_bounds = gpd.read_file(os.path.join(ADM_bound, \"NPL_ADM.gpkg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12208a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": "X:/Work/GeoTemp/CCDR/Nepal/data_script/cache/WorldPop20_NPL_ppp_UNadj_constrained.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\xarray\\backends\\lru_cache.py:53\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 53\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<function open at 0x000001D1E0290670>, ('X:/Work/GeoTemp/CCDR/Nepal/data_script/cache/WorldPop20_NPL_ppp_UNadj_constrained.tif',), 'r', (('sharing', False),)]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mrasterio\\_base.pyx:261\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\_shim.pyx:78\u001b[0m, in \u001b[0;36mrasterio._shim.open_dataset\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\_err.pyx:216\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: X:/Work/GeoTemp/CCDR/Nepal/data_script/cache/WorldPop20_NPL_ppp_UNadj_constrained.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m valid_RPs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m1000\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Open population dataset\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m pop_data \u001b[38;5;241m=\u001b[39m \u001b[43mrxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_rasterio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpop_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Indicate 0 values as representing no data.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m pop_data\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mwrite_nodata(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\rioxarray\\_io.py:833\u001b[0m, in \u001b[0;36mopen_rasterio\u001b[1;34m(filename, parse_coordinates, chunks, cache, lock, masked, mask_and_scale, variable, group, default_name, decode_times, decode_timedelta, **open_kwargs)\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    832\u001b[0m         manager \u001b[38;5;241m=\u001b[39m URIManager(rasterio\u001b[38;5;241m.\u001b[39mopen, filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mopen_kwargs)\n\u001b[1;32m--> 833\u001b[0m     riods \u001b[38;5;241m=\u001b[39m \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m     captured_warnings \u001b[38;5;241m=\u001b[39m rio_warnings\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# raise the NotGeoreferencedWarning if applicable\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\xarray\\backends\\file_manager.py:181\u001b[0m, in \u001b[0;36mCachingFileManager.acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;124;03m\"\"\"Acquire a file object from the manager.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03m    A new file is only opened if it has expired from the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m        An open file object, as returned by ``opener(*args, **kwargs)``.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     file, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\xarray\\backends\\file_manager.py:205\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    203\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    204\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 205\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overriden when opened again\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\rasterio\\env.py:437\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    434\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ccdr\\lib\\site-packages\\rasterio\\__init__.py:220\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;66;03m# Create dataset instances and pass the given env, which will\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# be taken over by the dataset's context manager if it is not\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# None.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 220\u001b[0m     s \u001b[38;5;241m=\u001b[39m DatasetReader(path, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    222\u001b[0m     s \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[0;32m    223\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mrasterio\\_base.pyx:263\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRasterioIOError\u001b[0m: X:/Work/GeoTemp/CCDR/Nepal/data_script/cache/WorldPop20_NPL_ppp_UNadj_constrained.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "valid_RPs = [10, 100, 1000]\n",
    "\n",
    "# Open population dataset\n",
    "pop_data = rxr.open_rasterio(pop_fn)\n",
    "\n",
    "# Indicate 0 values as representing no data.\n",
    "pop_data.rio.write_nodata(0, inplace=True)\n",
    "\n",
    "# Get raw array for population data\n",
    "pop_array = pop_data[0].values\n",
    "\n",
    "# Prep result structure\n",
    "adm_dataset = gpd.read_file(os.path.join(ADM_bound, \"NPL_ADM.gpkg\"), layer=\"ADM3\")\n",
    "adm2_data = adm_dataset.loc[adm_dataset.ADM0_CODE == country_code_map[country], :]\n",
    "\n",
    "# Create dataframe to hold results\n",
    "num_rows = len(adm2_data.index)\n",
    "adm_details = {\n",
    "    \"ADM3_CODE\": adm2_data.LOCAL,\n",
    "    \"ADM3_NAME\": adm2_data.LOCAL\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(adm_details)\n",
    "pop_sum_cols = [f\"RP{rp_i}_pop_sum\" for rp_i in valid_RPs]\n",
    "EAI_cols = [f\"RP{rp_i}_EAI\" for rp_i in valid_RPs]\n",
    "\n",
    "num_new_cols = len(pop_sum_cols + EAI_cols)\n",
    "result_df.loc[:, pop_sum_cols + EAI_cols] = np.array([np.zeros(num_rows), ] * num_new_cols).T\n",
    "\n",
    "\n",
    "for rp in valid_RPs:\n",
    "\n",
    "    # Load ADM2 based on country code value\n",
    "    adm3_data = adm_dataset.loc[adm_dataset.ADM0_CODE == country_code_map[country], :]\n",
    "\n",
    "    # Load corresponding flood dataset\n",
    "    flood_data = rxr.open_rasterio(flood_RP_data_loc+f\"RP{rp}.tif\")\n",
    "\n",
    "    # Reproject and clip raster to same bounds as population data\n",
    "    flood_data = flood_data.rio.reproject_match(pop_data)\n",
    "    flood_data = flood_data.rio.clip_box(*pop_data.rio.bounds())\n",
    "\n",
    "    # Get raw array values for population and flood\n",
    "    fld_array = flood_data[0].values\n",
    "    fld_array[fld_array < min_haz_threshold] = np.nan  # Set values below min threshold to nan\n",
    "    # fld_array[fld_array > max_haz_threshold] = max_haz_threshold  # Cap large values to maximum threshold value\n",
    "\n",
    "    # Assign impact factor\n",
    "    impact_array = damage_factor(fld_array)\n",
    "\n",
    "    # Create raster from array\n",
    "    impact_rst = xr.DataArray(np.array([impact_array]).astype(np.float32), coords=flood_data.coords, dims=flood_data.dims)\n",
    "    # impact_rst.plot()  # to preview\n",
    "\n",
    "    # Probability of return period\n",
    "    # Essentially the same as 1/RP, but accounts for cases where RP == 1\n",
    "    RPp = 1 - np.exp(-1/rp)\n",
    "\n",
    "    # For each ADM2 region\n",
    "    for row in result_df.itertuples():\n",
    "        geom = adm3_data.loc[adm2_data.ADM3_CODE == row.ADM3_CODE, \"geometry\"]\n",
    "\n",
    "        # Clip impacted dataset to current ADM2 region\n",
    "        rst = impact_rst.rio.clip(geom, adm3_data.crs)\n",
    "\n",
    "        # Determine population in ADM3\n",
    "        pop_clip = pop_data.rio.clip(geom, adm2_data.crs)\n",
    "        pop_arr = pop_clip.values\n",
    "        result_df.loc[result_df.ADM3_CODE == row.ADM3_CODE, \"ADM3_Pop\"] = pop_arr[(pop_arr > 0, )].sum()\n",
    "\n",
    "        # Calculate affected population in ADM2\n",
    "        tmp = pop_arr[(rst > 0, )]\n",
    "        affected_pop = tmp[tmp > 0].sum()\n",
    "\n",
    "        # Get Expected Annual Impact for given RP\n",
    "        RPi_EAI = affected_pop * RPp\n",
    "\n",
    "        # Save total population affected to dataframe\n",
    "        result_df.loc[result_df.ADM3_CODE == row.ADM3_CODE, f\"RP{rp}_pop_sum\"] = affected_pop\n",
    "\n",
    "        # Save EAI (affected population for a single year)\n",
    "        result_df.loc[result_df.ADM3_CODE == row.ADM3_CODE, f\"RP{rp}_EAI\"] = RPi_EAI\n",
    "\n",
    "\n",
    "# Sum all EAI to get total EAI across all RPs\n",
    "result_df.loc[:, \"Pop_EAI\"] = result_df.loc[:, result_df.columns.str.contains('_EAI')].sum(axis=1)\n",
    "\n",
    "# Calculate Pop_EAI%\n",
    "result_df.loc[:, \"Pop_EAI%\"] = result_df.loc[:, \"Pop_EAI\"] / result_df.loc[:, \"ADM3_Pop\"]  # Percent affected population per year\n",
    "\n",
    "# Aggregated to ADM1\n",
    "agg_func = getattr(np, agg_criteria)\n",
    "result_df.loc[:, f\"ADM1_agg_{agg_criteria}\"] = agg_func(result_df.loc[:, \"Pop_EAI%\"])\n",
    "\n",
    "# Write table of total population in each class, in each ADM2\n",
    "result_df.to_csv(f\"{country}_functional_example_results.csv\", index=False)\n",
    "\n",
    "# Join result dataframe to ADM2 vector data\n",
    "result_geom = adm3_data.merge(result_df, on=\"ADM2_CODE\")\n",
    "\n",
    "# Export geopackage\n",
    "result_geom.to_file(f\"{country}_ADM3.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2201d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d8b26c4f649b8a27f8996ac75dd87b5987470d4d00d1b2c02ba594e155f4b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
