{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f8d23db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPRE-REQUISITES - for demo, to be improved\\n\\n- ANACONDA and PYTHON INSTALLED\\n- RENAME RP FILES to RP10, RP100, RP1000\\n- HAVE ADM data with proper ADM_CODE and ADM_NAME COLS FOR ALL LEVELS!\\n- SET THE STRUCTURE OF FOLDERS AS REQUESTED\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PRE-REQUISITES - for demo, to be improved\n",
    "\n",
    "- ANACONDA and PYTHON INSTALLED\n",
    "- RENAME RP FILES to RP10, RP100, RP1000\n",
    "- HAVE ADM data with proper ADM_CODE and ADM_NAME COLS FOR ALL LEVELS!\n",
    "- SET THE STRUCTURE OF FOLDERS AS REQUESTED\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ad9a5b-154d-4f7a-8579-59487c6a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import tempfile, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from rasterstats import gen_zonal_stats\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import contextily as ctx\n",
    "# from contextily import Place\n",
    "\n",
    "# Addresses SSL error when interacting with worldpop data\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d53d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directories\n",
    "DATA_DIR = \"X:/Work/GeoTemp/CCDR/Nepal/data_script/\"\n",
    "ADM_bound = \"X:/Work/GeoTemp/CCDR/Nepal/data_script/adm\"\n",
    "\n",
    "\n",
    "# Common directories\n",
    "DATA_DIR = \"../data/\"\n",
    "SAR_loc = \"C:/development/CDCC-data/SAR/\"\n",
    "\n",
    "# Make cache dir if needed\n",
    "CACHE_DIR = f\"{DATA_DIR}cache/\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_factor(x):\n",
    "    \"\"\"A polynomial fit to average damage across multiple sectors relative \n",
    "    to water depth in meters in Asia.\n",
    "\n",
    "    The sectors are commercial, industry, transport, agriculture, infrastructure and residential.\n",
    "\n",
    "    Values are capped between 0 and 1, where values >= 6m = 1\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] JRC, 2017\n",
    "    \"\"\"\n",
    "    return np.maximum(0.0, np.minimum(1.0, 0.00723*x**3 - 0.1*x**2 + 0.506*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "526bfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stub for user input\n",
    "# TODO: Make this nicer and more accessible for users\n",
    "\n",
    "country = \"NPL\"\n",
    "exp_cat = [\"population\", \"land cover\"]\n",
    "# Population maps from worldpop are available for a range of years. Specify the year after checking for availability.\n",
    "# population_year = \"2020\"\n",
    "\n",
    "# Settings\n",
    "agg_criteria = \"mean\"  # [\"max\", \"mean\"]\n",
    "min_haz_threshold = 0.5  # determine min/max values from user-selected edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fc09e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data file locations\n",
    "# TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "\n",
    "# pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "pop_fn = f\"{DATA_DIR}/cache/WorldPop20_{country}_ppp_UNadj_constrained.tif\"\n",
    "\n",
    "# Flood data location (TODO: replace with pointer to downloaded data store)\n",
    "flood_RP_data_loc = f\"X:/Work/GeoTemp/CCDR/Nepal/data_script/\"\n",
    "flood_RP_data_loc = f\"C:/development/CDCC-data/SAR/HZD/Flood/{country}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24d7319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_map = {\n",
    "    \"NPL\": 175  # TODO: Add others\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "712e53bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or save ISO3 country list\n",
    "iso3_path = f\"{DATA_DIR}cache/iso3.json\"\n",
    "if not os.path.exists(iso3_path):\n",
    "    resp = json.loads(requests.get(f\"https://www.worldpop.org/rest/data/pop/wpgp?iso3={country}\").text)\n",
    "\n",
    "    with open(iso3_path, 'w') as outfile:\n",
    "        json.dump(resp, outfile)\n",
    "else:\n",
    "    with open(iso3_path, 'r') as infile:\n",
    "        resp = json.load(infile)\n",
    "\n",
    "\n",
    "# TODO: User to select population data set\n",
    "# Target population data files are extracted from the JSON list downloaded above\n",
    "metadata = resp['data'][1]\n",
    "data_src = metadata['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbbd775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\takuy\\AppData\\Local\\Temp\\ipykernel_18136\\695879328.py:10: UserWarning: Found 1591_npl_ppp_2001.tif in cache, skipping...\n",
      "  warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save population data to cache location\n",
    "for data_fn in tqdm(data_src):\n",
    "    fid = metadata['id']\n",
    "    cache_fn = os.path.basename(data_fn)\n",
    "\n",
    "    # Look for indicated file in cache directory\n",
    "    # Use the data file if it is found, but warn the user. \n",
    "    # (if data is incorrect or corrupted, they should delete it from cache)\n",
    "    if f\"{fid}_{cache_fn}\" in os.listdir(f\"{DATA_DIR}/cache\"):\n",
    "        warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Write to cache file if not found\n",
    "    with open(f\"{DATA_DIR}/cache/{fid}_{cache_fn}\", \"wb\") as handle:\n",
    "        response = requests.get(data_fn)\n",
    "        handle.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d21d7f",
   "metadata": {},
   "source": [
    "Load country boundaries from ADM geopackage file which includes ISO3 code related to country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f9101d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_bounds = gpd.read_file(os.path.join(ADM_bound, \"NPL_ADM.gpkg\"))\n",
    "country_bounds = gpd.read_file(os.path.join(DATA_DIR, \"NPL_ADM.gpkg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66ea1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_RPs = [10, 100, 1000]\n",
    "\n",
    "# Open population dataset\n",
    "pop_data = rxr.open_rasterio(pop_fn)\n",
    "\n",
    "# Indicate -1 values as representing no data.\n",
    "pop_data.rio.write_nodata(-1, inplace=True)\n",
    "\n",
    "# Load ADM2 based on country code value\n",
    "adm_dataset = gpd.read_file(os.path.join(DATA_DIR, \"NPL_ADM.gpkg\"), layer=\"ADM3\")\n",
    "adm_data = adm_dataset.loc[adm_dataset.ADM0_CODE == country_code_map[country], :]\n",
    "\n",
    "# Prep result structure\n",
    "pop_sum_cols = [f\"RP{rp_i}_pop_sum\" for rp_i in valid_RPs]\n",
    "EAI_cols = [f\"RP{rp_i}_EAI\" for rp_i in valid_RPs]\n",
    "result_df = adm_data.loc[:, [\"ADM3_CODE\", \"ADM3_NAME\", \"geometry\"]]\n",
    "result_df.loc[:, pop_sum_cols + EAI_cols] = 0\n",
    "\n",
    "pop_bounds = pop_data.rio.bounds()\n",
    "\n",
    "crs = result_df.crs\n",
    "for rp in valid_RPs:\n",
    "    \n",
    "    # Get total population for each ADM2 region\n",
    "    pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=pop_fn, stats=[\"sum\"])\n",
    "    \n",
    "    result_df[\"ADM3_Pop\"] = [x['sum'] for x in pop_per_ADM]\n",
    "\n",
    "    # Load corresponding flood dataset\n",
    "    flood_data = rxr.open_rasterio(flood_RP_data_loc+f\"RP{rp}.tif\")\n",
    "\n",
    "    # Reproject and clip raster to same bounds as population data\n",
    "    flood_data = flood_data.rio.reproject_match(pop_data)\n",
    "\n",
    "    # Get raw array values for population and flood\n",
    "    fld_array = flood_data[0].values\n",
    "    fld_array[fld_array < min_haz_threshold] = np.nan  # Set values below min threshold to nan\n",
    "    # fld_array[fld_array > max_haz_threshold] = max_haz_threshold  # Cap large values to maximum threshold value\n",
    "\n",
    "    # Assign impact factor\n",
    "    impact_array = damage_factor(fld_array)\n",
    "\n",
    "    # Create raster from array\n",
    "    impact_rst = xr.DataArray(np.array([impact_array]).astype(np.float32), coords=flood_data.coords, dims=flood_data.dims)\n",
    "    # impact_rst.plot()  # to preview\n",
    "\n",
    "    # Impact x Pop\n",
    "    # Calculate affected population in ADM3\n",
    "    affected_pop = pop_data.where(impact_rst.values > 0)\n",
    "    affected_pop = affected_pop.where(affected_pop > 0)\n",
    "\n",
    "    # Probability of return period\n",
    "    # Essentially the same as 1/RP, but accounts for cases where RP == 1\n",
    "    RPp = 1 - np.exp(-1/rp)\n",
    "\n",
    "    RPi_EAI = affected_pop * RPp\n",
    "\n",
    "    # Get affected population per ADM\n",
    "    affected_pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=affected_pop.data[0], \n",
    "                                           stats=[\"sum\"], affine=affected_pop.rio.transform(), nodata=np.nan)\n",
    "    result_df[f\"RP{rp}_pop_sum\"] = [x['sum'] for x in affected_pop_per_ADM]\n",
    "\n",
    "\n",
    "    EAI_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=RPi_EAI.data[0], \n",
    "                                  stats=[\"sum\"], affine=RPi_EAI.rio.transform(), nodata=np.nan)\n",
    "    result_df[f\"RP{rp}_EAI\"] = [x['sum'] for x in EAI_per_ADM]\n",
    "\n",
    "        \n",
    "# Sum all EAI to get total EAI across all RPs\n",
    "result_df.loc[:, \"Pop_EAI\"] = result_df.loc[:, result_df.columns.str.contains('_EAI')].sum(axis=1)\n",
    "\n",
    "# Calculate Pop_EAI%\n",
    "result_df.loc[:, \"Pop_EAI%\"] = result_df.loc[:, \"Pop_EAI\"] / result_df.loc[:, \"ADM3_Pop\"]  # Percent affected population per year\n",
    "\n",
    "# Aggregated to ADM1\n",
    "agg_func = getattr(np, agg_criteria)\n",
    "result_df.loc[:, f\"ADM1_agg_{agg_criteria}\"] = agg_func(result_df.loc[:, \"Pop_EAI%\"])\n",
    "\n",
    "# Write table of total population in each class, in each ADM2\n",
    "result_df.to_csv(f\"{country}_functional_example_results.csv\", index=False)\n",
    "\n",
    "# Export geopackage\n",
    "result_df.to_file(f\"{country}_ADM3_test2.gpkg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42334e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac41a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d8b26c4f649b8a27f8996ac75dd87b5987470d4d00d1b2c02ba594e155f4b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
