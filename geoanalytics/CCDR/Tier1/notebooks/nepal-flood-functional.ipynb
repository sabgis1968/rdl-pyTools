{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ad9a5b-154d-4f7a-8579-59487c6a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *  # import necessary packages\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d53d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directories\n",
    "DATA_DIR = \"../data/\"\n",
    "SAR_loc = \"C:/development/CDCC-data/SAR/\"\n",
    "\n",
    "# Make cache dir if needed\n",
    "CACHE_DIR = f\"{DATA_DIR}cache/\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6738bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_map = {\n",
    "    \"NPL\": 175  # TODO: Add others\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_factor(x):\n",
    "    \"\"\"A polynomial fit to average damage across multiple sectors relative \n",
    "    to water depth in meters in Asia.\n",
    "\n",
    "    The sectors are commercial, industry, transport, agriculture, infrastructure and residential.\n",
    "\n",
    "    Values are capped between 0 and 1, where values >= 6m = 1\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] JRC, 2017\n",
    "    \"\"\"\n",
    "    return np.maximum(0.0, np.minimum(1.0, 0.00723*x**3 - 0.1*x**2 + 0.506*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53ebd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(bt):\n",
    "    with output:\n",
    "        print(\"Running analysis...\")\n",
    "        bt.disabled = True\n",
    "\n",
    "    # Get user input\n",
    "    country = country_dd.value\n",
    "    exp_cat = exp_cat_dd.value\n",
    "    time_horizon = time_horizon_dd.value\n",
    "    rcp_scenario = rcp_scenario_dd.value\n",
    "\n",
    "    target_ADM = adm_dd.value\n",
    "    adm_name = target_ADM.replace('_', '')\n",
    "\n",
    "    agg_criteria = agg_dd.value\n",
    "    min_haz_threshold = min_haz_slider.value\n",
    "\n",
    "    valid_RPs = [10, 100, 1000]\n",
    "\n",
    "    # Testing data file locations\n",
    "    # TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "\n",
    "    # pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "    pop_fn = f\"{DATA_DIR}/cache/WorldPop20_{country}_ppp_UNadj_constrained.tif\"\n",
    "\n",
    "    # Flood data location (TODO: replace with pointer to\n",
    "    #  downloaded data store)\n",
    "    flood_RP_data_loc = f\"C:/development/CDCC-data/SAR/HZD/Flood/{country}/\"\n",
    "\n",
    "    # Load or save ISO3 country list\n",
    "    iso3_path = f\"{DATA_DIR}cache/iso3.json\"\n",
    "    if not os.path.exists(iso3_path):\n",
    "        resp = json.loads(requests.get(f\"https://www.worldpop.org/rest/data/pop/wpgp?iso3={country}\").text)\n",
    "\n",
    "        with open(iso3_path, 'w') as outfile:\n",
    "            json.dump(resp, outfile)\n",
    "    else:\n",
    "        with open(iso3_path, 'r') as infile:\n",
    "            resp = json.load(infile)\n",
    "\n",
    "\n",
    "    # TODO: User to select population data set\n",
    "    # Target population data files are extracted from the JSON list downloaded above\n",
    "    metadata = resp['data'][1]\n",
    "    data_src = metadata['files']\n",
    "\n",
    "    # Save population data to cache location\n",
    "    for data_fn in tqdm(data_src):\n",
    "        fid = metadata['id']\n",
    "        cache_fn = os.path.basename(data_fn)\n",
    "\n",
    "        # Look for indicated file in cache directory\n",
    "        # Use the data file if it is found, but warn the user. \n",
    "        # (if data is incorrect or corrupted, they should delete it from cache)\n",
    "        if f\"{fid}_{cache_fn}\" in os.listdir(f\"{DATA_DIR}/cache\"):\n",
    "            warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Write to cache file if not found\n",
    "        with open(f\"{DATA_DIR}/cache/{fid}_{cache_fn}\", \"wb\") as handle:\n",
    "            response = requests.get(data_fn)\n",
    "            handle.write(response.content)\n",
    "\n",
    "\n",
    "    # Run analysis\n",
    "    \n",
    "    # Open population dataset\n",
    "    pop_data = rxr.open_rasterio(pop_fn)\n",
    "\n",
    "    # Indicate -1 values as representing no data.\n",
    "    pop_data.rio.write_nodata(-1, inplace=True)\n",
    "\n",
    "    # Load ADM2 based on country code value\n",
    "    try:\n",
    "        adm_dataset = gpd.read_file(os.path.join(SAR_loc, \"ADM_012.gpkg\"), layer=target_ADM)\n",
    "    except ValueError:\n",
    "        # Layer names have not been standardized yet, so try again without the underscore\n",
    "        adm_dataset = gpd.read_file(os.path.join(SAR_loc, \"NPL_ADM.gpkg\"), layer=adm_name)\n",
    "\n",
    "    \n",
    "    adm_data = adm_dataset.loc[adm_dataset.ADM0_CODE == country_code_map[country], :]\n",
    "\n",
    "    # Prep result structure\n",
    "    pop_sum_cols = [f\"RP{rp_i}_pop_sum\" for rp_i in valid_RPs]\n",
    "    EAI_cols = [f\"RP{rp_i}_EAI\" for rp_i in valid_RPs]\n",
    "    result_df = adm_data.loc[:, [f\"{adm_name}_CODE\", f\"{adm_name}_NAME\", \"geometry\"]]\n",
    "    result_df.loc[:, pop_sum_cols + EAI_cols] = 0\n",
    "\n",
    "    # pop_bounds = pop_data.rio.bounds()\n",
    "    # crs = result_df.crs\n",
    "    for rp in valid_RPs:\n",
    "        \n",
    "        # Get total population for each ADM2 region\n",
    "        pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=pop_fn, stats=[\"sum\"])\n",
    "        \n",
    "        result_df[f\"{adm_name}_Pop\"] = [x['sum'] for x in pop_per_ADM]\n",
    "\n",
    "        # Load corresponding flood dataset\n",
    "        flood_data = rxr.open_rasterio(flood_RP_data_loc+f\"RP{rp}.tif\")\n",
    "\n",
    "        # Reproject and clip raster to same bounds as population data\n",
    "        flood_data = flood_data.rio.reproject_match(pop_data)\n",
    "\n",
    "        # Get raw array values for population and flood\n",
    "        fld_array = flood_data[0].values\n",
    "        fld_array[fld_array < min_haz_threshold] = np.nan  # Set values below min threshold to nan\n",
    "        # fld_array[fld_array > max_haz_threshold] = max_haz_threshold  # Cap large values to maximum threshold value\n",
    "\n",
    "        # Assign impact factor (this is F_i)\n",
    "        impact_array = damage_factor(fld_array)\n",
    "\n",
    "        # Create raster from array\n",
    "        impact_rst = xr.DataArray(np.array([impact_array]).astype(np.float32), \n",
    "                                  coords=flood_data.coords, \n",
    "                                  dims=flood_data.dims)\n",
    "        # impact_rst.plot()  # to preview\n",
    "\n",
    "        # Calculate affected population in ADM        \n",
    "        # Filter down to valid areas\n",
    "        valid_impact_areas = impact_rst.values > 0\n",
    "        affected_pop = pop_data.where(valid_impact_areas)  # Get population in affected areas\n",
    "        affected_pop = affected_pop.where(affected_pop > 0)  # Out of the above, get areas that have people\n",
    "        \n",
    "        # Calculate M_pop_i\n",
    "        impact_pop = affected_pop * impact_rst.where(valid_impact_areas)\n",
    "        \n",
    "        impact_pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=impact_pop.data[0], \n",
    "                                             stats=[\"sum\"], affine=impact_pop.rio.transform(), nodata=-999)\n",
    "        result_df[f\"RP{rp}_pop\"] = [x['sum'] for x in impact_pop_per_ADM]\n",
    "        \n",
    "        # Sum of impacted population for entire country\n",
    "        # result_df[f\"RP{rp}_pop\"] = np.nansum(impact_pop[0].data)\n",
    "\n",
    "        # Probability of return period\n",
    "        # Essentially the same as 1/RP, but accounts for cases where RP == 1\n",
    "        freq = 1 - np.exp(-1/rp)\n",
    "\n",
    "        # EAI_i := F_i * freq\n",
    "        EAI_i = impact_rst.where(valid_impact_areas) * freq\n",
    "\n",
    "        # Get affected population per ADM\n",
    "        affected_pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=affected_pop.data[0], \n",
    "                                            stats=[\"sum\"], affine=affected_pop.rio.transform(), nodata=-999)\n",
    "        result_df[f\"RP{rp}_pop_sum\"] = [x['sum'] for x in affected_pop_per_ADM]\n",
    "\n",
    "\n",
    "        EAI_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=EAI_i.data[0],\n",
    "                                    stats=[\"sum\"], affine=EAI_i.rio.transform(), nodata=-999)\n",
    "        result_df[f\"RP{rp}_EAI\"] = [x['sum'] for x in EAI_per_ADM]\n",
    "\n",
    "    # Sum all EAI to get total EAI across all RPs\n",
    "    result_df.loc[:, \"Pop_EAI\"] = result_df.loc[:, result_df.columns.str.contains('_EAI')].sum(axis=1)\n",
    "\n",
    "    # Calculate Pop_EAI%\n",
    "    result_df.loc[:, \"Pop_EAI%\"] = result_df.loc[:, \"Pop_EAI\"] / result_df.loc[:, f\"{adm_name}_Pop\"]  # Percent affected population per year\n",
    "\n",
    "    # Aggregated to ADM1\n",
    "    agg_func = getattr(np, agg_criteria)\n",
    "    result_df.loc[:, f\"ADM1_agg_{agg_criteria}\"] = agg_func(result_df.loc[:, \"Pop_EAI%\"])\n",
    "\n",
    "    # Write table of total population in each class, in each ADM2\n",
    "    df_cols = result_df.columns\n",
    "    result_df.loc[:, df_cols[~df_cols.isin(['geometry'])]].to_csv(f\"{country}_functional_example_results.csv\", index=False)\n",
    "\n",
    "    # Export geopackage\n",
    "    result_df.to_file(f\"{country}_{adm_name}_test.gpkg\")\n",
    "    \n",
    "    with output:\n",
    "        print(\"Finished analysis.\")\n",
    "        bt.disabled = False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "526bfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dd = widgets.Dropdown(\n",
    "    options=[('Nepal', 'NPL'), ],\n",
    "    value='NPL',\n",
    "    description='Country:',\n",
    ")\n",
    "\n",
    "exp_cat_dd = widgets.Dropdown(\n",
    "    options=[(\"Population\", \"population\"), (\"Land Cover\", \"land_cover\")],\n",
    "    value='population',\n",
    "    description='Exposure Category:',\n",
    ")\n",
    "\n",
    "time_horizon_dd = widgets.Dropdown(\n",
    "    options=[2050, 2080],\n",
    "    value=2050,\n",
    "    description='Time Horizon:',\n",
    ")\n",
    "\n",
    "rcp_scenario_dd = widgets.Dropdown(\n",
    "    options=[\"2.6\", \"4.5\", \"6.5\", \"8.5\"],\n",
    "    value=\"4.5\",\n",
    "    description='RCP Scenario:',\n",
    ")\n",
    "\n",
    "adm_dd = widgets.Dropdown(\n",
    "    options=['ADM_1', 'ADM_2', 'ADM_3'],\n",
    "    value='ADM_2',\n",
    "    description='ADM Level:',\n",
    ")\n",
    "\n",
    "agg_dd = widgets.Dropdown(\n",
    "    options=['mean', 'max'],\n",
    "    value='mean',\n",
    "    description='Aggregation method:',\n",
    "    tooltip='Method to aggregate up to ADM1',\n",
    ")\n",
    "\n",
    "min_haz_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.01,\n",
    "    max=10.0,\n",
    "    step=0.05,\n",
    "    description=\"Minimum Threshold:\",\n",
    ")\n",
    "\n",
    "\n",
    "# Run button to perform analysis\n",
    "run_button = widgets.Button(\n",
    "    description='Run Analysis',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to run analysis with selected options',\n",
    "    # icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "# Button to preview analysis\n",
    "preview_button = widgets.Button(\n",
    "    description='Preview',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to preview results',\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "run_button.on_click(run_analysis)\n",
    "\n",
    "# preview_button.on_click()\n",
    "\n",
    "# class_range = range(3, 11)  # remember that python uses end-exclusive range, so this is 3-10\n",
    "# selected_bin_edges = [0.5, 1, 1.5, 2, 2.5, 3]\n",
    "# min_haz_threshold = np.min(selected_bin_edges)  # determine min/max values from user-selected edges\n",
    "# max_haz_threshold = np.max(selected_bin_edges)\n",
    "# selected_bin_edges += [np.inf] # add inf last to cover anything above max threshold.\n",
    "\n",
    "# num_bins = len(selected_bin_edges)-1  # default number of bins, within the range of `class_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59a0428c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b73044b754ff49218b7082e7ce4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Country:', options=(('Nepal', 'NPL'),), value='NPL')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03eb7b12670f4c89b976cb43d352c88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Exposure Category:', options=(('Population', 'population'), ('Land Cover', 'land_cover')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9507bfd83c2742a7a5a8a24f8a4431bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Time Horizon:', options=(2050, 2080), value=2050)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3764bcdd69143979880d7e02bdaec42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='RCP Scenario:', index=1, options=('2.6', '4.5', '6.5', '8.5'), value='4.5')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4afe03e72123450eb7500642e94d0165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='ADM Level:', index=1, options=('ADM_1', 'ADM_2', 'ADM_3'), value='ADM_2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dd4f3a99694a35ab2a8de4428a01c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Aggregation method:', options=('mean', 'max'), value='mean')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070e394df2c8435dabdb068dca7c92d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, description='Minimum Threshold:', max=10.0, min=0.01, step=0.05)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4338fcd6d21e443bac1bd1e02211f82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Run Analysis', style=ButtonStyle(), tooltip='Click to run analysis with sel…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945158e4f9e143eda5c4978298bec182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]C:\\Users\\takuy\\AppData\\Local\\Temp\\ipykernel_20552\\2388015749.py:56: UserWarning: Found 1591_npl_ppp_2001.tif in cache, skipping...\n",
      "  warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 501.11it/s]\n"
     ]
    }
   ],
   "source": [
    "display(country_dd)\n",
    "display(exp_cat_dd)\n",
    "display(time_horizon_dd)\n",
    "display(rcp_scenario_dd)\n",
    "display(adm_dd)\n",
    "display(agg_dd)\n",
    "display(min_haz_slider)\n",
    "\n",
    "display(HBox([run_button, preview_button]))\n",
    "\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c55043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d8b26c4f649b8a27f8996ac75dd87b5987470d4d00d1b2c02ba594e155f4b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
