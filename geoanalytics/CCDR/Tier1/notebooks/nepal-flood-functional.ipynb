{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ad9a5b-154d-4f7a-8579-59487c6a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import tempfile, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import contextily as ctx\n",
    "# from contextily import Place\n",
    "\n",
    "# Addresses SSL error when interacting with worldpop data\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d53d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common directories\n",
    "DATA_DIR = \"../data/\"\n",
    "SAR_loc = \"C:/development/CDCC-data/SAR/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_factor(x):\n",
    "    \"\"\"A polynomial fit to average damage across multiple sectors relative \n",
    "    to water depth in meters in Asia.\n",
    "\n",
    "    The sectors are commercial, industry, transport, agriculture, infrastructure and residential.\n",
    "\n",
    "    Values are capped between 0 and 1.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] JRC, 2017\n",
    "    \"\"\"\n",
    "    return np.maximum(0.0, np.minimum(1.0, 0.00723*x**3 - 0.1*x**2 + 0.506*x + 0.023))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526bfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stub for user input\n",
    "# TODO: Make this nicer and more accessible for users\n",
    "\n",
    "country = \"NPL\"\n",
    "exp_cat = [\"population\", \"land cover\"]\n",
    "time_horizon = [2050, 2080]\n",
    "rcp_scenario = [\"2.6\", \"4.5\", \"6.5\", \"8.5\"]\n",
    "\n",
    "# Settings\n",
    "agg_criteria = [\"max\", \"mean\"]\n",
    "class_range = range(3, 11)  # remember that python uses end-exclusive range, so this is 3-10\n",
    "\n",
    "selected_bin_edges = [0.5, 1, 1.5, 2, 2.5, 3]\n",
    "min_haz_threshold = np.min(selected_bin_edges)  # determine min/max values from user-selected edges\n",
    "max_haz_threshold = np.max(selected_bin_edges)\n",
    "selected_bin_edges += [np.inf]\n",
    "\n",
    "num_bins = len(selected_bin_edges)-1  # default number of bins, within the range of `class_range`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d21d7f",
   "metadata": {},
   "source": [
    "Load country boundaries from ADM geopackage file which includes ISO3 code related to country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12208a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_RPs = [10, 100, 1000]\n",
    "rp = 100  # selected RP for testing\n",
    "\n",
    "\n",
    "country_bounds = gpd.read_file(os.path.join(SAR_loc, \"ADM_012.gpkg\"))\n",
    "\n",
    "adm2_RP_dataset = gpd.read_file(os.path.join(SAR_loc, f\"ADM2_RP{rp}.gpkg\"))\n",
    "\n",
    "# TODO: Make ADM2 selection more generic for flexible notebooks\n",
    "# Currently hardcoding country selection (175 == Nepal)\n",
    "npl_adm2 = adm2_RP_dataset.loc[adm2_RP_dataset.ADM0_CODE == 175, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de057831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or save ISO3 country list\n",
    "iso3_path = f\"{DATA_DIR}cache/iso3.json\"\n",
    "if not os.path.exists(iso3_path):\n",
    "    resp = json.loads(requests.get(f\"https://www.worldpop.org/rest/data/pop/wpgp?iso3={country}\").text)\n",
    "\n",
    "    with open(iso3_path, 'w') as outfile:\n",
    "        json.dump(resp, outfile)\n",
    "else:\n",
    "    with open(iso3_path, 'r') as infile:\n",
    "        resp = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7d71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: User to select population data set\n",
    "# Target population data files are extracted from the JSON list downloaded above\n",
    "metadata = resp['data'][1]\n",
    "data_src = metadata['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30bddccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\takuy\\AppData\\Local\\Temp\\ipykernel_11428\\2709350986.py:6: UserWarning: Found 1591_npl_ppp_2001.tif in cache, skipping...\n",
      "  warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save population data to cache location\n",
    "for data_fn in tqdm(data_src):\n",
    "    fid = metadata['id']\n",
    "    cache_fn = os.path.basename(data_fn)\n",
    "    if f\"{fid}_{cache_fn}\" in os.listdir(f\"{DATA_DIR}/cache\"):\n",
    "        warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # write to file\n",
    "    with open(f\"{DATA_DIR}/cache/{fid}_{cache_fn}\", \"wb\") as handle:\n",
    "        response = requests.get(data_fn)\n",
    "        handle.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f33a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING FILE\n",
    "# pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "pop_fn = f\"{DATA_DIR}/cache/WorldPop20_NPL_ppp_UNadj_constrained.tif\"\n",
    "pop_data = rxr.open_rasterio(pop_fn)\n",
    "\n",
    "\n",
    "# TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "flood_RP_data_loc = \"C:/development/CDCC-data/SAR/HZD/Flood/NPL/\"\n",
    "\n",
    "flood_data = rxr.open_rasterio(flood_RP_data_loc+f\"RP{rp}.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9ecf58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\programs\\miniconda3\\envs\\ccdr-hazard\\lib\\site-packages\\rioxarray\\raster_writer.py:108: UserWarning: The nodata value (3.402823466e+38) has been automatically changed to (3.4028234663852886e+38) to match the dtype of the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "valid_RPs = [10, 100, 1000]\n",
    "rp = 100  # selected RP for testing\n",
    "\n",
    "# TESTING FILE\n",
    "# pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "pop_fn = f\"{DATA_DIR}/cache/WorldPop20_NPL_ppp_UNadj_constrained.tif\"\n",
    "pop_data = rxr.open_rasterio(pop_fn, masked=True)\n",
    "\n",
    "\n",
    "# TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "flood_RP_data_loc = \"C:/development/CDCC-data/SAR/HZD/Flood/NPL/\"\n",
    "flood_data = rxr.open_rasterio(flood_RP_data_loc+f\"RP{rp}.tif\", masked=True)\n",
    "\n",
    "# Reproject and clip raster to same bounds as population data\n",
    "flood_data = flood_data.rio.reproject_match(pop_data)\n",
    "flood_data = flood_data.rio.clip_box(*pop_data.rio.bounds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8969c0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to hold results\n",
    "num_rows = len(npl_adm2.index)\n",
    "adm_details = {\n",
    "    \"ADM2_CODE\": npl_adm2.ADM2_CODE,\n",
    "    \"ADM2_NAME\": npl_adm2.ADM2_NAME\n",
    "}\n",
    "\n",
    "# Specify initial columns for each RP\n",
    "affected_pop_cols = {f\"RP{rp_i}_pop_sum\": np.zeros(num_rows) for rp_i in valid_RPs}\n",
    "eai_cols = {f\"RP{rp_i}_EAI\": np.zeros(num_rows) for rp_i in valid_RPs}\n",
    "\n",
    "# Merge dictionaries and create dataframe\n",
    "df_details = adm_details | affected_pop_cols | eai_cols\n",
    "\n",
    "result_df = pd.DataFrame(df_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe3185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full raster of bin classes\n",
    "pop_array = pop_data[0].values\n",
    "fld_array = flood_data[0].values\n",
    "\n",
    "# fld_array[np.isnan(fld_array)] = 0  # Set NaNs to 0\n",
    "fld_array[fld_array < min_haz_threshold] = np.nan  # Set values below min threshold to nan\n",
    "# fld_array[fld_array > max_haz_threshold] = max_haz_threshold  # Cap large values to maximum threshold value\n",
    "\n",
    "# Assign impact factor\n",
    "impact_array = damage_factor(fld_array)\n",
    "\n",
    "# Create raster from array (for preview)\n",
    "impact_rst = xr.DataArray(np.array([impact_array]).astype(np.float32), coords=flood_data.coords, dims=flood_data.dims)\n",
    "\n",
    "# impact_rst.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8730a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data.rio.write_nodata(0, inplace=True)\n",
    "\n",
    "# Probability of return period\n",
    "# Essentially the same as 1/RP, but accounts for cases where RP == 1\n",
    "RPp = 1 - np.exp(-1/rp)\n",
    "\n",
    "for row in result_df.itertuples():\n",
    "    geom = npl_adm2.loc[npl_adm2.ADM2_CODE == row.ADM2_CODE, \"geometry\"]\n",
    "\n",
    "    rst = impact_rst.rio.clip(geom, npl_adm2.crs)\n",
    "\n",
    "    pop_clip = pop_data.rio.clip(geom, npl_adm2.crs)\n",
    "    pop_arr = pop_clip.values\n",
    "\n",
    "    affected_pop = pop_arr[(rst >= 0, )].sum()  # RPi_pop\n",
    "    total_pop_in_ADM2 = pop_clip.sum()\n",
    "\n",
    "    # Get EAI for RP\n",
    "    RPi_EAI = affected_pop * RPp\n",
    "\n",
    "    # Save total population affected to dataframe\n",
    "    result_df.loc[result_df.ADM2_CODE == row.ADM2_CODE, f\"RP{rp}_pop_sum\"] = affected_pop\n",
    "\n",
    "    # Save EAI\n",
    "    result_df.loc[result_df.ADM2_CODE == row.ADM2_CODE, f\"RP{rp}_EAI\"] = RPi_EAI\n",
    "\n",
    "\n",
    "# ... after each RP ...\n",
    "# Sum all RPi_EAI columns for each ADM2: table [ADM2; RP_Pop_EAI]\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba0c460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write table of total population in each class, in each ADM2\n",
    "result_df.to_csv(\"npl_RP100_functional_example_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e497f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d8b26c4f649b8a27f8996ac75dd87b5987470d4d00d1b2c02ba594e155f4b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
