{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba77d7d",
   "metadata": {},
   "source": [
    "CCDR Hazard Analysis Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ad9a5b-154d-4f7a-8579-59487c6a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *  # import necessary packages\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6738bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_map = {\n",
    "    \"NPL\": 175,\n",
    "    \"PAK\": 188 # TODO: Add others\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181ff7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_factor(x):\n",
    "    \"\"\"A polynomial fit to average damage across multiple sectors relative \n",
    "    to water depth in meters in Asia.\n",
    "\n",
    "    The sectors are commercial, industry, transport, agriculture, infrastructure and residential.\n",
    "\n",
    "    Values are capped between 0 and 1, where values >= 6m = 1\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] JRC, 2017\n",
    "    \"\"\"\n",
    "    return np.maximum(0.0, np.minimum(1.0, 0.00723*x**3 - 0.1*x**2 + 0.506*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ca2a71-2a12-4859-afb7-7479f3a37b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_impact_func(bt):\n",
    "    steps = np.arange(0, 6, 0.1)\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        line, = ax.plot([damage_factor(x) for x in steps])\n",
    "        ax.grid(True)\n",
    "        \n",
    "        label_steps = range(0, len(steps)+10, 10)\n",
    "        ax.xaxis.set_ticks(label_steps)\n",
    "        ax.xaxis.set_ticklabels([i / 10 for i in label_steps])\n",
    "        ax.set_xlabel(\"Depth\")\n",
    "        ax.set_ylabel(\"Impact Factor\")\n",
    "        \n",
    "        display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ebd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(rb):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Running analysis...\")\n",
    "        rb.disabled = True\n",
    "        preview_impact_button.disabled = True\n",
    "\n",
    "    # Get user input\n",
    "    country = country_dd.value\n",
    "    exp_cat = exp_cat_dd.value\n",
    "    time_horizon = time_horizon_dd.value\n",
    "    rcp_scenario = rcp_scenario_dd.value\n",
    "\n",
    "    target_ADM = adm_dd.value\n",
    "    adm_name = target_ADM.replace('_', '')\n",
    "\n",
    "    agg_criteria = agg_dd.value\n",
    "    min_haz_threshold = min_haz_slider.value\n",
    "\n",
    "    valid_RPs = [10, 100, 1000]\n",
    "\n",
    "    # Testing data file locations\n",
    "    # TODO: Temp data store, to be replaced with a config spec (.env file?) before deployment\n",
    "\n",
    "    # pop_fn = f\"{DATA_DIR}/cache/{fid}_{cache_fn}\"\n",
    "    pop_fn = f\"{DATA_DIR}/cache/WorldPop20_{country}_ppp_UNadj_constrained.tif\"\n",
    "\n",
    "    # Flood data location (TODO: replace with pointer to\n",
    "    #  downloaded data store)\n",
    "    flood_RP_data_loc = f\"{DATA_DIR}\"\n",
    "\n",
    "    # Load or save ISO3 country list\n",
    "    iso3_path = os.path.join(DATA_DIR, \"cache/iso3.json\")\n",
    "    if not os.path.exists(iso3_path):\n",
    "        resp = json.loads(requests.get(f\"https://www.worldpop.org/rest/data/pop/wpgp?iso3={country}\").text)\n",
    "\n",
    "        with open(iso3_path, 'w') as outfile:\n",
    "            json.dump(resp, outfile)\n",
    "    else:\n",
    "        with open(iso3_path, 'r') as infile:\n",
    "            resp = json.load(infile)\n",
    "\n",
    "\n",
    "    # TODO: User to select population data set\n",
    "    # Target population data files are extracted from the JSON list downloaded above\n",
    "    metadata = resp['data'][1]\n",
    "    data_src = metadata['files']\n",
    "\n",
    "    # Save population data to cache location\n",
    "    for data_fn in tqdm(data_src):\n",
    "        fid = metadata['id']\n",
    "        cache_fn = os.path.basename(data_fn)\n",
    "\n",
    "        # Look for indicated file in cache directory\n",
    "        # Use the data file if it is found, but warn the user. \n",
    "        # (if data is incorrect or corrupted, they should delete it from cache)\n",
    "        if f\"{fid}_{cache_fn}\" in os.listdir(CACHE_DIR):\n",
    "            warnings.warn(f\"Found {fid}_{cache_fn} in cache, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Write to cache file if not found\n",
    "        with open(os.path.join(CACHE_DIR, \"{fid}_{cache_fn}\"), \"wb\") as handle:\n",
    "            response = requests.get(data_fn)\n",
    "            handle.write(response.content)\n",
    "\n",
    "\n",
    "    # Run analysis\n",
    "    \n",
    "    # Open population dataset\n",
    "    pop_data = rxr.open_rasterio(pop_fn)\n",
    "\n",
    "    # Indicate -1 values as representing no data.\n",
    "    pop_data.rio.write_nodata(-1, inplace=True)\n",
    "\n",
    "    # Load ADM2 based on country code value\n",
    "    try:\n",
    "        adm_dataset = gpd.read_file(os.path.join(DATA_DIR, \"SAR_ADM.gpkg\"), layer=f\"{country}_{adm_name}\")\n",
    "    except ValueError:\n",
    "        # Using national ADM layer if the regional one is not avaialble\n",
    "        adm_dataset = gpd.read_file(os.path.join(DATA_DIR, f\"{country}_ADM.gpkg\"), layer=f\"{country}_{adm_name}\")\n",
    "\n",
    "    \n",
    "    adm_data = adm_dataset.loc[adm_dataset.ADM0_CODE == country_code_map[country], :]\n",
    "\n",
    "    # Prep result structure\n",
    "    pop_sum_cols = [f\"RP{rp_i}_pop_tot\" for rp_i in valid_RPs]\n",
    "    EAI_cols = [f\"RP{rp_i}_EAI\" for rp_i in valid_RPs]\n",
    "    \n",
    "    # Get all ADM code/name columns to save with results\n",
    "    adm_cols = adm_data.columns\n",
    "    all_adm_codes = adm_data.columns.str.contains(\"_CODE\")\n",
    "    all_adm_names = adm_data.columns.str.contains(\"_NAME\")\n",
    "    \n",
    "    all_adm_name_tmp = adm_cols[all_adm_names].tolist()\n",
    "    all_adm_code_tmp = adm_cols[all_adm_codes].to_list()\n",
    "\n",
    "    result_df = adm_data.loc[:, all_adm_code_tmp + all_adm_name_tmp + [\"geometry\"]]\n",
    "    result_df.loc[:, pop_sum_cols + EAI_cols] = 0\n",
    "\n",
    "    for rp in valid_RPs:\n",
    "        \n",
    "        # Get total population for each ADM2 region\n",
    "        pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=pop_fn, stats=[\"sum\"])\n",
    "        \n",
    "        result_df[f\"{adm_name}_Pop\"] = [x['sum'] for x in pop_per_ADM]\n",
    "\n",
    "        # Load corresponding flood dataset\n",
    "        flood_data = rxr.open_rasterio(os.path.join(flood_RP_data_loc, f\"{country}_RP{rp}.tif\"))\n",
    "\n",
    "        # Reproject and clip raster to same bounds as population data\n",
    "        flood_data = flood_data.rio.reproject_match(pop_data)\n",
    "\n",
    "        # Get raw array values for population and flood\n",
    "        fld_array = flood_data[0].values\n",
    "        fld_array[fld_array < min_haz_threshold] = np.nan  # Set values below min threshold to nan\n",
    "        # fld_array[fld_array > max_haz_threshold] = max_haz_threshold  # Cap large values to maximum threshold value\n",
    "\n",
    "        # Assign impact factor (this is F_i)\n",
    "        # TODO: Change this function call to use the relevant function depending on `exp_cat_dd`\n",
    "        if exp_cat_dd.value == 'population':\n",
    "            impact_array = damage_factor(fld_array)\n",
    "        elif exp_cat_dd.value == 'built_up':\n",
    "            pass\n",
    "        elif exp_cat_dd.value == 'agri':\n",
    "            pass\n",
    "        else:\n",
    "            ValueError(\"Unknown exposure category\")\n",
    "\n",
    "        # Create raster from array\n",
    "        impact_rst = xr.DataArray(np.array([impact_array]).astype(np.float32), \n",
    "                                  coords=flood_data.coords, \n",
    "                                  dims=flood_data.dims)\n",
    "        \n",
    "        if save_inter_rst_chk.value:\n",
    "            impact_rst.rio.to_raster(os.path.join(OUTPUT_DIR, \"impact.tif\"))\n",
    "\n",
    "        # Calculate affected population in ADM        \n",
    "        # Filter down to valid areas\n",
    "        valid_impact_areas = impact_rst.values > 0\n",
    "        affected_pop = pop_data.where(valid_impact_areas)  # Get total population in affected areas\n",
    "        affected_pop = affected_pop.where(affected_pop > 0)  # Out of the above, get areas that have people\n",
    "        \n",
    "        if save_inter_rst_chk.value:\n",
    "            affected_pop.rio.to_raster(os.path.join(OUTPUT_DIR, f\"affected_pop_{rp}.tif\"))\n",
    "        \n",
    "        # Calculate degree on impact over Exposure category\n",
    "        impact_pop = affected_pop * impact_rst.where(valid_impact_areas)  # Get impacted population in affected areas\n",
    "        \n",
    "        if save_inter_rst_chk.value:\n",
    "            impact_pop.rio.to_raster(os.path.join(OUTPUT_DIR, f\"impact_pop_{rp}.tif\"))\n",
    "        \n",
    "        impact_pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=impact_pop.data[0], \n",
    "                                             stats=[\"sum\"], affine=impact_pop.rio.transform(), nodata=0)\n",
    "        result_df[f\"RP{rp}_pop_imp\"] = [x['sum'] for x in impact_pop_per_ADM]\n",
    "        \n",
    "        # Sum of impacted population for entire country\n",
    "        # result_df[f\"RP{rp}_pop\"] = np.nansum(impact_pop[0].data)\n",
    "\n",
    "        # Probability of return period\n",
    "        # Essentially the same as 1/RP, but accounts for cases where RP == 1\n",
    "        freq = 1 - np.exp(-1/rp)\n",
    "\n",
    "        # EAI_i := F_i * freq\n",
    "        EAI_i = impact_pop.where(valid_impact_areas) * freq\n",
    "        \n",
    "\n",
    "        if save_inter_rst_chk.value:\n",
    "            # Save intermediate file if requested\n",
    "            EAI_i.rio.to_raster(os.path.join(OUTPUT_DIR, f\"EAI_{rp}.tif\"))\n",
    "\n",
    "        # Get affected population per ADM\n",
    "        affected_pop_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=affected_pop.data[0], \n",
    "                                            stats=[\"sum\"], affine=affected_pop.rio.transform(), nodata=0)\n",
    "        result_df[f\"RP{rp}_pop_tot\"] = [x['sum'] for x in affected_pop_per_ADM]\n",
    "\n",
    "\n",
    "        EAI_per_ADM = gen_zonal_stats(vectors=adm_data[\"geometry\"], raster=EAI_i.data[0],\n",
    "                                    stats=[\"sum\"], affine=EAI_i.rio.transform(), nodata=0)\n",
    "        result_df[f\"RP{rp}_EAI\"] = [x['sum'] for x in EAI_per_ADM]\n",
    "\n",
    "    # Sum all EAI to get total EAI across all RPs\n",
    "    result_df.loc[:, \"Pop_EAI\"] = result_df.loc[:, result_df.columns.str.contains('_EAI')].sum(axis=1)\n",
    "\n",
    "    # Calculate Pop_EAI% (Percent affected population per year)\n",
    "    result_df.loc[:, \"Pop_EAI%\"] = (result_df.loc[:, \"Pop_EAI\"] / result_df.loc[:, f\"{adm_name}_Pop\"]) * 100.0\n",
    "\n",
    "    # Aggregated to ADM1\n",
    "    # agg_func = getattr(np, agg_criteria)\n",
    "    # result_df.loc[:, f\"ADM1_agg_{agg_criteria}\"] = agg_func(result_df.loc[:, \"Pop_EAI%\"])\n",
    "    \n",
    "    # Round to two decimal places to avoid giving the impression of high precision\n",
    "    result_df = result_df.round(2)\n",
    "    \n",
    "    # Reorder - need ADM code, name, and pop at the front regardless of ADM level\n",
    "    cols = result_df.columns\n",
    "    adm_pop = cols.str.contains(\"_Pop\")\n",
    "    adm_pop = cols[adm_pop].tolist()\n",
    "\n",
    "    result_df = result_df.loc[:, all_adm_code_tmp + all_adm_name_tmp + adm_pop +\n",
    "                                  [\"RP10_pop_tot\", \"RP100_pop_tot\", \"RP1000_pop_tot\", \n",
    "                                  \"RP10_pop_imp\", \"RP100_pop_imp\", \"RP1000_pop_imp\", \n",
    "                                  \"RP10_EAI\", \"RP100_EAI\", \"RP1000_EAI\", \n",
    "                                  \"Pop_EAI\", \"Pop_EAI%\", \"geometry\"]]\n",
    "\n",
    "    # Write table of total population in each class, in each ADM2\n",
    "    df_cols = result_df.columns\n",
    "    result_df.loc[:, df_cols[~df_cols.isin(['geometry'])]].fillna(0).to_csv(os.path.join(OUTPUT_DIR, f\"{country}_{adm_name}_flood_EAI.csv\"), index=False)\n",
    "\n",
    "    # Export geopackage\n",
    "    result_df.to_file(os.path.join(OUTPUT_DIR, f\"{country}_{adm_name}_flood_EAI.gpkg\"))\n",
    "\n",
    "    with output:\n",
    "        print(\"Finished analysis.\")\n",
    "        rb.disabled = False\n",
    "    \n",
    "    if preview_chk.value:\n",
    "        with output:\n",
    "            display(result_df.explore(column='Pop_EAI', cmap='plasma'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "526bfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data option widgets\n",
    "country_dd = widgets.Dropdown(\n",
    "    options=[('Nepal', 'NPL'), ('Pakistan', 'PAK'),('Bangladesh', 'BGD'),],\n",
    "    value='NPL',\n",
    "    description='Country:',\n",
    ")\n",
    "\n",
    "exp_cat_dd = widgets.Dropdown(\n",
    "    options=[(\"Population\", \"population\"), (\"Built-up\", \"built_up\"), (\"Agriculture\", \"agri\")],\n",
    "    value='population',\n",
    "    description='Exposure Category:',\n",
    ")\n",
    "\n",
    "time_horizon_dd = widgets.Dropdown(\n",
    "    options=[2050, 2080],\n",
    "    value=2050,\n",
    "    description='Time Horizon:',\n",
    ")\n",
    "\n",
    "rcp_scenario_dd = widgets.Dropdown(\n",
    "    options=[\"2.6\", \"4.5\", \"6.5\", \"8.5\"],\n",
    "    value=\"4.5\",\n",
    "    description='RCP Scenario:',\n",
    ")\n",
    "\n",
    "adm_dd = widgets.Dropdown(\n",
    "    options=['ADM1', 'ADM2', 'ADM3'],\n",
    "    value='ADM2',\n",
    "    description='ADM Level:',\n",
    ")\n",
    "\n",
    "agg_dd = widgets.Dropdown(\n",
    "    options=['mean', 'max'],\n",
    "    value='mean',\n",
    "    description='Aggregation method:',\n",
    "    tooltip='Method to aggregate up to ADM1',\n",
    ")\n",
    "\n",
    "min_haz_slider = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0.01,\n",
    "    max=10.0,\n",
    "    step=0.01,\n",
    "    description=\"Minimum Threshold:\",\n",
    ")\n",
    "\n",
    "\n",
    "# User action widgets\n",
    "save_inter_rst_chk = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Export Intermediate Rasters',\n",
    "    tooltip='Save rasters generated between each step (saves to nominated output directory)',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "# Display results after runs\n",
    "preview_chk = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Preview results',\n",
    "    tooltip='Display result after analysis',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "# Run button to perform analysis\n",
    "run_button = widgets.Button(\n",
    "    description='Run Analysis',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to run analysis with selected options',\n",
    "    # icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "# Button to preview hazard impact function\n",
    "preview_impact_button = widgets.Button(\n",
    "    description='Preview Impact Function',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Show preview of impact function',\n",
    "    # icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "reset_display_button = widgets.Button(\n",
    "    description='Reset',\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Reset display',\n",
    "    # icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "def reset_display(bt):\n",
    "    output.clear_output()\n",
    "    run_button.disabled = False\n",
    "    preview_impact_button.disabled = False\n",
    "\n",
    "run_button.on_click(run_analysis)\n",
    "preview_impact_button.on_click(preview_impact_func)\n",
    "reset_display_button.on_click(reset_display)\n",
    "\n",
    "# preview_button.on_click()\n",
    "\n",
    "# class_range = range(3, 11)  # remember that python uses end-exclusive range, so this is 3-10\n",
    "# selected_bin_edges = [0.5, 1, 1.5, 2, 2.5, 3]\n",
    "# min_haz_threshold = np.min(selected_bin_edges)  # determine min/max values from user-selected edges\n",
    "# max_haz_threshold = np.max(selected_bin_edges)\n",
    "# selected_bin_edges += [np.inf] # add inf last to cover anything above max threshold.\n",
    "\n",
    "# num_bins = len(selected_bin_edges)-1  # default number of bins, within the range of `class_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a0428c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a224749bfb3348afb504575aa82fac82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Country:', options=(('Nepal', 'NPL'), ('Pakistan', 'PAK'), ('Bangladesh', 'BGD')), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77eb782c098742a5a5a3365f10f28e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Exposure Category:', options=(('Population', 'population'), ('Built-up', 'built_up'), ('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ea29c9c2634ae68c29caacda8d08a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Time Horizon:', options=(2050, 2080), value=2050)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d883006f1175415591d8a02ce6f47318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='RCP Scenario:', index=1, options=('2.6', '4.5', '6.5', '8.5'), value='4.5')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599664435d294cb08e7731897ed7f74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='ADM Level:', index=1, options=('ADM1', 'ADM2', 'ADM3'), value='ADM2')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f341785673b9416a9ea4341f80bd9ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, description='Minimum Threshold:', max=10.0, min=0.01, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7ee69a4c834feb847a565c4666ce1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Run Analysis', style=ButtonStyle(), tooltip='Click to run analysis with sel…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fde15f67aef4281b9290538c9a750f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Preview Impact Function', style=ButtonStyle(), tooltip='Show preview of impact function')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aee8a0ab9546919aae03792526ee1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset', style=ButtonStyle(), tooltip='Reset display')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706d0120e49c455a94f847857688e77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(country_dd)\n",
    "display(exp_cat_dd)\n",
    "display(time_horizon_dd)\n",
    "display(rcp_scenario_dd)\n",
    "display(adm_dd)\n",
    "# display(agg_dd)\n",
    "display(min_haz_slider)\n",
    "\n",
    "display(HBox([run_button, preview_chk, save_inter_rst_chk]), \n",
    "        preview_impact_button, reset_display_button)\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579cdc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6d8b26c4f649b8a27f8996ac75dd87b5987470d4d00d1b2c02ba594e155f4b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
